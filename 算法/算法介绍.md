# 一、

## KNN算法-邻近算法

来源：https://aistudio.baidu.com/projectdetail/619297?ad-from=1742

这次简要介绍knn算法和具体实现的案例代码，依旧会是很基础并且不会刻意利用python的高级特性。

整个内容大概分成三个部分，knn介绍，python实现，和进阶方法。

不论你现在熟悉哪种语言，感兴趣的话都可以动手自己尝试一下。

### 一、KNN介绍

在我看来，knn就是计算测试数据与每一个训练数据的距离，取出距离最近的K个训练数据的标签，以其中数量最多的作为测试数据的预测标签。

官方地说：

邻近算法，或者说K最近邻(kNN，k-NearestNeighbor)分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。Cover和Hart在1968年提出了最初的邻近算法。KNN是一种分类(classification)算法，它输入基于实例的学习（instance-based learning），属于懒惰学习（lazy  learning）即KNN没有显式的学习过程，也就是说没有训练阶段，数据集事先已有了分类和特征值，待收到新样本后直接进行处理。与急切学习（eager learning）相对应。

KNN是通过测量不同特征值之间的距离进行分类。

思路是：如果一个样本在特征空间中的k个最邻近的样本中的大多数属于某一个类别，则该样本也划分为这个类别。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。

提到KNN，网上最常见的就是下面这个图。

我们要确定绿点属于哪个颜色（红色或者蓝色），要做的就是选出距离目标点距离最近的k个点，看这k个点的大多数颜色是什么颜色。当k取3的时候，我们可以看出距离最近的三个，分别是红色、红色、蓝色，因此得到目标点为红色。

![img](https://ai-studio-static-online.cdn.bcebos.com/8bb692e864c74d8098e22d6946ca5405bbf5f0b010b846ba9499d9e505f233d1)

#### 算法流程：

1）计算测试数据与各个训练数据之间的距离；

2）按照距离的递增关系进行排序；

3）选取距离最小的K个点；

4）确定前K个点所在类别的出现频率；

5）返回前K个点中出现频率最高的类别作为测试数据的预测分类

#### K的取值

K：临近数，即在预测目标点时取几个临近的点来预测。

K值得选取非常重要，因为：

如果当K的取值过小时，一旦有噪声得成分存在们将会对预测产生比较大影响，例如取K值为1时，一旦最近的一个点是噪声，那么就会出现偏差，K值的减小就意味着整体模型变得复杂，容易发生过拟合；

如果K的值取的过大时，就相当于用较大邻域中的训练实例进行预测，学习的近似误差会增大。这时与输入目标点较远实例也会对预测起作用，使预测发生错误。K值的增大就意味着整体的模型变得简单；

如果K==N的时候，那么就是取全部的实例，即为取实例中某分类下最多的点，就对预测没有什么实际的意义了；

K的取值尽量要取**奇数**，以保证在计算结果最后会产生一个较多的类别，如果取偶数可能会产生相等的情况，不利于预测。

常用的方法是从k=1开始，使用检验集估计分类器的误差率。重复该过程，每次K增值1，允许增加一个近邻。选取产生最小误差率的K。一般k的取值不超过20，上限是n的开方，随着数据集的增大，K的值也要增大。

# 二、

来源：https://zhuanlan.zhihu.com/p/544911041?utm_id=0

## 递归算法

> **递归算法**：是一种直接或者间接地调用自身的算法。在计算机编写程序中，递归算法对解决一大类问题是十分有效的，它往往使算法的描述简洁而且易于理解。

递归过程一般通过函数或子过程来实现。

**递归算法的实质**：是把问题转化为规模缩小了的同类问题的子问题。然后递归调用函数(或过程)来表示问题的解。

**递归算法解决问题的特点**：

1. 　　递归就是在过程或函数里调用自身。
2. 　　在使用递归策略时，必须有一个明确的递归结束条件，称为递归出口。
3. 　　递归算法解题通常显得很简洁，但递归算法解题的运行效率较低。所以一般不提倡用递归算法设计程序。
4. 　　在递归调用的过程当中系统为每一层的返回点、局部变量等开辟了栈来存储。递归次数过多容易造成栈溢出

等。所以一般不提倡用递归算法设计程序。

## 排序算法

> 排序是程序设计中常做的操作，初学者往往只知道冒泡排序算法，其实还有很多效率更高的排序算法，比如希尔排序、快速排序、基数排序、归并排序等。
> 不同的排序算法，适用于不同的场景，本章最后从时间性能，算法稳定性等方面，分析各种排序算法。
> 排序算法，还分为内部排序算法和外部排序算法，之间的区别是，前者在内存中完成排序，而后者则需要借助外部存储器。
> 这里介绍的是内部排序算法。

### 冒泡排序：

起泡排序，别名“冒泡排序”，该算法的核心思想是将无序表中的所有记录，通过两两比较关键字，得出升序序列或者降序序列。

![image-20240826173138603](imge/算法介绍.assets/image-20240826173138603.png)

### 快速排序：

> 快速排序算法是在起泡排序的基础上进行改进的一种算法，
> 其实现的基本思想是：通过一次排序将整个无序表分成相互独立的两部分，其中一部分中的数据都比另一部分中包含的数据的值小，然后继续沿用此方法分别对两部分进行同样的操作，
> 直到每一个小部分不可再分，所得到的整个序列就成为了有序序列。

![image-20240826173338794](imge/算法介绍.assets/image-20240826173338794.png)

## 二分查找算法

> 二分査找就是折半查找，
> 其基本思想是：首先选取表中间位置的记录，将其关键字与给定关键字 key 进行比较，若相等，则査找成功；
> 若 key 值比该关键字值大，则要找的元素一定在右子表中，则继续对右子表进行折半查找；
> 若 key 值比该关键宇值小，则要找的元素一定在左子表中，继续对左子表进行折半査找。
> 如此递推，直到査找成功或査找失败（或査找范围为 0）。

例如：

要求用户输入数组长度，也就是有序表的数据长度，并输入数组元素和査找的关键字。

程序输出查找成功与否，以及成功时关键字在数组中的位置。

例如，在有序表 11、13、18、 28、39、56、69、89、98、122 中査找关键字为 89 的元素。

![image-20240826173603528](imge/算法介绍.assets/image-20240826173603528.png)

## 搜索算法

> 搜索算法是利用计算机的高性能来有目的的穷举一个问题解空间的部分或所有的可能情况，从而求出问题的解的一种方法。
> 现阶段一般有枚举算法、深度优先搜索、广度优先搜索、A*算法、回溯算法、蒙特卡洛树搜索、散列函数等算法。
> 在大规模实验环境中，通常通过在搜索前，根据条件降低搜索规模；
> 根据问题的约束条件进行剪枝；利用搜索过程中的中间解，避免重复计算这几种方法进行优化。

## **深度优先搜索**

- 深度优先遍历首先访问出发点v，并将其标记为已访问过；然后依次从v出发搜索v的每个邻接点w。若w未曾访问过，则以w为新的出发点继续进行深度优先遍历，直至图中所有和源点v有路径相通的顶点均已被访问为止。
- 若此时图中仍有未访问的顶点，则另选一个尚未访问的顶点作为新的源点重复上述过程，直至图中所有顶点均已被访问为止。

深度搜索与广度搜索的相近，最终都要扩展一个结点的所有子结点。

> 　　区别在于对扩展结点过程，深度搜索扩展的是E-结点的邻接结点中的一个，并将其作为新的E-结点继续扩展，当前E-结点仍为活结点，待搜索完其子结点后，回溯到该结点扩展它的其它未搜索的邻接结点。
> 而广度搜索，则是扩展E-结点的所有邻接结点，E-结点就成为一个死结点。

## 哈希算法

**1. 什么是哈希**

Hash，一般翻译做散列、杂凑，或音译为哈希，是一个典型的利用空间换取时间的算法，把任意长度的输入（又叫做预映射pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值。

如有一个学生信息表：

学生的学号为：年纪+学院号+班级号+顺序排序号【如：19(年纪)+002(2号学院)+01(一班)+17(17号)---à190020117】类似于一个这样的信息，当我们需要找到这个学号为【190020117】的学生，在不适用哈希的时候，我们通常是使用一个顺序遍历的方式在数据中进行查询大类，再查询子类得到，这样的作法很明显不够快 ，需要O(n)左右的时间花费，对于大型的数据规模而言这显然不行，而哈希的做法是，根据一定的规律(比如说年纪不存在过老和过小的情况，以此将【190020117】进行压缩成一个简短的数据如：

【192117】)并且将这个数据直接作用于内存的地址，届时我们查询【190020117】只需要进行一次压缩并访问【192117】这个地址即可，而这个压缩的方法（函数），就可以称之为哈希函数

一般的对于哈希函数需要考虑如下内容:

1. 计算散列地址所需要的时间（即hash函数本身不要太复杂）
2. 关键字的长度
3. 表长(不宜过长或过短，避免内存浪费和算力消耗)
4. 关键字分布是否均匀，是否有规律可循
5. 设计的hash函数在满足以上条件的情况下尽量减少冲突

**2.哈希与哈希表**

在理解了哈希的思维之后，我们要了解什么是哈希表，哈希表顾名思义就是经过哈希函数进行转换后的一张表，通过访问哈希表，我们可以快速查询哈希表，从而得出所需要得到的数据，构建哈希表的核心就是要考虑哈希函数的冲突处理（即经过数据压缩之后可能存在多数据同一个地址，需要利用算法将冲突的数据分别存储）。

冲突处理的方法有很多，最简单的有+1法，即地址数直接+1，当两个数据都需要存储进【2019】时，可以考虑将其中的一个存进【2020】此外还有，开放定址法，链式地址发，公共溢出法，再散列法，质数法等等，各方法面对不同的数据特征有不同的效果。



**3.哈希的思维**

Hash算法是一个广义的算法，也可以认为是一种思想，使用Hash算法可以提高存储空间的利用率，可以提高数据的查询效率，也可以做数字签名来保障数据传递的安全性。

所以Hash算法被广泛地应用在互联网应用中。

比如，利用哈希的思维在O(1)的复杂度情况下任意查询1000以内所有的质数（在创建是否是质数的时候并不是O(1)的复杂度），

注意本样例只是演示思维，面对本需求可以有更好的空间利用方式（本写法比较浪费空间，仅供了解）

如下例子：

**【电话聊天狂人】**

给定大量手机用户通话记录，找出其中通话次数最多的聊天狂人。

**输入格式:**
输入首先给出正整数N（≤105​​），为通话记录条数。随后N行，每行给出一条通话记录。简单起见，这里只列出拨出方和接收方的11位数字构成的手机号码，其中以空格分隔。

**输出格式:**
在一行中给出聊天狂人的手机号码及其通话次数，其间以空格分隔。如果这样的人不唯一，则输出狂人中最小的号码及其通话次数，并且附加给出并列狂人的人数。
**输入样例：**

> 4
> 13005711862 13588625832
> 13505711862 13088625832
> 13588625832 18087925832
> 15005713862 13588625832

**输出样例：**

> 13588625832 3

## 贪心算法

> 贪心算法（又称贪婪算法）是指，在对问题求解时，总是做出在当前看来是最好的选择。
> 也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。
> 贪心算法不是对所有问题都能得到整体最优解，但对范围相当广泛的许多问题他能产生整体最优解或者是整体最优解的近似解。

贪心算法的基本思路是从问题的某一个初始解出发一步一步地进行，根据某个优化测度，每一步都要确保能获得局部最优解。每一步只考虑一个数据，他的选取应该满足局部优化的条件，直到把所有数据枚举完。

贪心算法的思想如下：

1. 建立数学模型来描述问题；
2. 把求解的问题分成若干个子问题；
3. 对每一子问题求解，得到子问题的局部最优解；
4. 把子问题的解局部最优解合成原来解问题的一个解。

与动态规划不同的是，贪心算法得到的是一个局部最优解（即有可能不是最理想的），而动态规划算法得到的是一个全局最优解（即必须是整体而言最理想的），

一个有趣的事情是，动态规划中的01背包问题就是一个典型的贪心算法问题。

如下例子：**贪心算法货币统计问题**

![image-20240826175544849](imge/算法介绍.assets/image-20240826175544849.png)

## 分治算法

分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。
求出子问题的解，就可得到原问题的解。即一种分目标完成程序算法

> 简单问题可用二分法完成。

#### 归并排序

时间复杂度是O(NlogN)O(Nlog⁡N)，空间复制度为O(N)O(N)（归并排序的最大缺陷）
归并排序（Merge Sort）完全遵循上述分治法

三个步骤：

1. 分解：将要排序的n个元素的序列分解成两个具有n/2个元素的子序列；
2. 解决：使用归并排序分别递归地排序两个子序列；
3. 合并：合并两个已排序的子序列，产生原问题的解。

## 回溯算法

> 回溯算法，又称为“试探法”。解决问题时，每进行一步，都是抱着试试看的态度，如果发现当前选择并不是最好的，或者这么走下去肯定达不到目标，立刻做回退操作重新选择。
> 这种走不通就回退再走的方法就是回溯算法。

例如，在解决列举集合 {1,2,3} 中所有子集的问题中，就可以使用回溯算法。

从集合的开头元素开始，对每个元素都有两种选择：取还是舍。当确定了一个元素的取舍之后，再进行下一个元素，直到集合最后一个元素。

其中的每个操作都可以看作是一次尝试，每次尝试都可以得出一个结果。将得到的结果综合起来，就是集合的所有子集。

很多人认为回溯和递归是一样的，其实不然。在回溯法中可以看到有递归的身影，但是两者是有区别的。
回溯法从问题本身出发，寻找可能实现的所有情况。和穷举法的思想相近，不同在于穷举法是将所有的情况都列举出来以后再一一筛选，而回溯法在列举过程如果发现当前情况根本不可能存在，就停止后续的所有工作，返回上一步进行新的尝试。
递归是从问题的结果出发，例如求 n！，要想知道 n！的结果，就需要知道 n*(n-1)! 的结果，而要想知道 (n-1)! 结果，就需要提前知道 (n-1)*(n-2)!。这样不断地向自己提问，不断地调用自己的思想就是递归。

使用回溯法解决问题的过程，实际上是建立一棵“状态树”的过程。

例如，在解决列举集合{1,2,3}所有子集的问题中，对于每个元素，都有两种状态，取还是舍，所以构建的状态树为：

![image-20240826180214100](imge/算法介绍.assets/image-20240826180214100.png)

回溯算法的求解过程实质上是先序遍历“状态树”的过程。树中每一个叶子结点，都有可能是问题的答案。图 1 中的状态树是满二叉树

，得到的叶子结点全部都是问题的解。

在某些情况下，回溯算法解决问题的过程中创建的状态树并不都是满二叉树，因为在试探的过程中，有时会发现此种情况下，

再往下进行没有意义，所以会放弃这条死路，回溯到上一步。在树中的体现，就是在树的最后一层不是满的，即不是满二叉树，需要自己判断哪些叶子结点代表的是正确的结果。

## 动态规划(DP)算法

> 动态规划过程：每一次决策依赖于当前的状态，即下一状态的产生取决于当前状态。一个决策序列就是在变化的状态中产生的，这种多阶段最优化问题的求解过程就是动态规则过程。

**基本思想原理**

与分而治之原理类似，将待求解的问题划分成若干个子问题（阶段）求解，顺序求解各个子问题（阶段），前一子问题（阶段）为后一子问题（阶段）的求解提供有用的信息。

通过各个子问题（阶段）的求解，依次递进，最终得到初始问题的解。一般情况下，能够通过动态规划求解的问题也可通过递归求解。

动态规划求解的问题多数有重叠子问题的特点，为了减少重复计算，对每个子问题只求解一次，将不同子问题（阶段）的解保存在数组中。

**与分而治之的区别**：

> 分而治之得到的若干子问题（阶段）一般彼此独立，各个子问题（阶段）之间没有顺序要求。而动态规划中各子问题（阶段）求解有顺序要求，具有重叠子问题（阶段），后一子问题（阶段）求解取决于前一子问题（阶段）的解。

**与递归区别：**

> 与递归求解区别不大，都是划分成各个子问题（阶段），后一子问题（阶段）取决于前一子问题（阶段），但递归需要反复求解同一个子问题（阶段），相较于动态规划做了很多重复性工作。

**适用解决问题**

采用动态规划求解的问题一般具有如下性质：

1. 最优化原理：求解问题包含最优子结构，即，可由前一子问题（阶段）最优推导得出后一子问题（阶段）最优解，递进得到初始问题的最优解。
2. 无后效性：某状态以后的过程不会影响以前的状态，只与当前状态有关。

有重叠子问题：子问题（阶段）之间不是独立的，一个子问题（阶段）的解在下一子问题（阶段）中被用到。（不是必需的条件，但是动态规划优于其他方法的基础）

比如斐波那契数列，就是一个简单的例子。

定义：

```text
Fab(n)= Fab(n-1)+Fab(n-2)
Fab(1)=Fab(2)=1;
```

假如我们求Fab(5) 。那我们需要求Fab（4） +Fab（3）。

Fab(4) =Fab(3) + Fab(2).....显然。 Fab（3）被计算机不加区别的计算了两次。而且随着数字的增大，计算量是指数增长的。

如果我们使用一个数组，记录下Fab的值。当Fab(n)!=null 时。

直接读取。那么，我们就能把时间复杂度控制在 n 以内。

## 字符串匹配算法

字符串匹配问题的形式定义：

- **文本（Text）**是一个长度为 n 的数组 T[1..n]；
- **模式（Pattern）**是一个长度为 m 且 m≤n 的数组 P[1..m]；
- T 和 P 中的元素都属于有限的**字母表 Σ 表**；
- 如果 0≤s≤n-m，并且 T[s+1..s+m] = P[1..m]，即对 1≤j≤m，有 T[s+j] = P[j]，则说模式 P 在文本 T 中出现且位移为 s，且称 s 是一个**有效位移（Valid Shift）**。

![image-20240826181654872](imge/算法介绍.assets/image-20240826181654872.png)

比如上图中，目标是找出所有在文本 T = abcabaabcabac 中模式 P = abaa 的所有出现。

该模式在此文本中仅出现一次，即在位移 s = 3 处，位移 s = 3 是有效位移。

解决字符串匹配的算法包括：

1. 朴素算法（Naive Algorithm）、
2. Rabin-Karp 算法、
3. 有限自动机算法（Finite Automation）、
4. Knuth-Morris-Pratt 算法（即 KMP Algorithm）、Boyer-Moore 算法、Simon 算法、Colussi 算法、Galil-Giancarlo  算法、Apostolico-Crochemore 算法、Horspool 算法和 Sunday 算法等。

字符串匹配算法通常分为两个步骤：预处理（Preprocessing）和匹配（Matching）。所以算法的总运行时间为预处理和匹配的时间的总和。

![image-20240826181905017](imge/算法介绍.assets/image-20240826181905017.png)

# 三、

来源：https://baijiahao.baidu.com/s?id=1793233085347019870&wfr=spider&for=pc

## 傅里叶变换与快速傅里叶变换：宇宙之音的解码器

它是现代通信的基石，无论是在你的智能手机中，还是在远在太空的卫星通信中，FFT都在确保信息以最清晰的形式传递

## 迪杰斯特拉算法：寻找知识海洋中的最短航线

迪杰斯特拉算法是一种经典的寻路算法，它如同一位经验丰富的航海家，能够在复杂的网络中找到两点间的最短路径。在你使用地图软件规划路线时，在每一个数据包在互联网中寻找目的地时，迪杰斯特拉算法都在默默地发挥作用。

## RSA算法：数字世界的守护者

在这个信息泄露的时代，RSA算法就像是守护秘密的骑士，它利用数学中的质数之美来构建一座安全的城堡。无论是保护你的在线交易，还是加密你的私人通信，RSA算法都确保只有持有钥匙的人才能解开信息的锁链。

## 安全散列算法：数字身份的指纹

安全散列算法（如MD5、SHA-1和SHA-2）是网络世界的指纹鉴定法，它可以将任意长度的数据压缩成一段固定长度的唯一序列。正如每个人的指纹都是独一无二的，安全散列算法确保每一份数据都能被准确地验证，从而防止了数据被篡改的可能。

## 整数因数分解：密码学中的哥德尔不完备定理

整数因数分解问题是现代密码学的基础之一，它的难解性保证了加密信息的安全。这一问题就像数学中的哥德尔不完备定理，表明了我们知识的界限，在这个界限之内，我们能够构建起几乎不可能破解的密码体系。

## 链接分析：网络世界的社会学家

链接分析算法是互联网时代的社会学家，它能够分析网页之间的关系，就像研究社会网络中人与人之间的联系。这些算法，如谷歌的PageRank，通过评估链接的质量和数量，决定了网页在搜索结果中的排名。在社交媒体的海洋中，它们分析我们的连接和互动，帮助发现影响力者并优化广告投放。

![image-20240826182829169](imge/算法介绍.assets/image-20240826182829169.png)

## 比例积分微分算法（PID）：现代自动控制的大师

PID算法是控制理论的灵魂，无论是在保持飞机的稳定飞行，还是在自动驾驶汽车中维持车速和方向，PID算法都在其中起着至关重要的作用。这个算法组合了过去（比例），现在（积分）和未来（微分）的信息，以创造出一个平衡的响应系统。

## 数据压缩算法：数字世界的压缩魔术师

在我们的设备和网络中，存储空间和带宽都是宝贵的资源。数据压缩算法，像是JPEG图像压缩、MPEG视频压缩、ZIP文件压缩和MP3音频压缩，它们就像是魔术师，能够在不损失太多品质的情况下，将大量信息压缩成更小的空间。这使得我们能够在数字高速公路上更快地传输数据，并在我们的设备上存储更多的记忆。

## 随机数生成：宇宙混沌的数字化

在加密、游戏设计、人工智能和金融模型中，随机数生成是创造不可预测性的基石。这些算法是现代版的掷骰子，确保每一次的结果都是公平且随机的，从而为我们的数字决策提供了一个坚实的基础。

# 四、

来源：https://www.bilibili.com/video/BV1wa4y117PC?p=9&vd_source=d6c3edd9a4f6205095ccfba6b2a61eec

线性回归

逻辑回归

梯度下降

SVM支持向量机

随机森林

决策树

贝叶斯

聚类算法

朴树贝叶斯

神经网络